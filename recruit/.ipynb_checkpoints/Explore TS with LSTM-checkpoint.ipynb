{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8bd41f5e-8931-42ef-a440-072078a72531",
    "_uuid": "b86dc252887403d87ab2d04cf965801ffc41a3b1"
   },
   "source": [
    "In this notebook I'll try the approach, which discovered in one tutorial about multivariate time series forecasting using LSTM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "725ec533-357d-45cb-ba91-6af034696543",
    "_uuid": "e2058e19bb6a2b4a8bfdb0740a1b371092b0b476"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(17)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5f9b6c6e-bc43-411e-a9d8-0ed4cb746074",
    "_uuid": "604b6bd57b7c254f7014abb079667f5a350f2694"
   },
   "source": [
    "## **Data Aggregation**\n",
    "\n",
    "\n",
    "Features from **the1owl**'s kernel https://www.kaggle.com/the1owl/surprise-me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "cac9e094-3b2f-471e-8bb2-5a6967bb3790",
    "_uuid": "98e8cdbccba65e193d36603a77d483e00480e949",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'tra': pd.read_csv('input/air_visit_data.csv'),\n",
    "    'as': pd.read_csv('input/air_store_info.csv'),\n",
    "    'hs': pd.read_csv('input/hpg_store_info.csv'),\n",
    "    'ar': pd.read_csv('input/air_reserve.csv'),\n",
    "    'hr': pd.read_csv('input/hpg_reserve.csv'),\n",
    "    'id': pd.read_csv('input/store_id_relation.csv'),\n",
    "    'tes': pd.read_csv('input/sample_submission.csv'),\n",
    "    'hol': pd.read_csv('input/date_info.csv').rename(columns={'calendar_date':'visit_date'})\n",
    "    }\n",
    "\n",
    "data['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "09486f7b-8b1f-47a3-b2b8-17fefc08ae0f",
    "_uuid": "623d2a29ababd1a2ff8ade01bcec2af814d4f33b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for df in ['ar','hr']:\n",
    "    data[df]['visit_datetime'] = pd.to_datetime(data[df]['visit_datetime'])\n",
    "    data[df]['visit_datetime'] = data[df]['visit_datetime'].dt.date\n",
    "    data[df]['reserve_datetime'] = pd.to_datetime(data[df]['reserve_datetime'])\n",
    "    data[df]['reserve_datetime'] = data[df]['reserve_datetime'].dt.date    \n",
    "    data[df]['reserve_datetime_diff'] = data[df].apply(lambda r: (r['visit_datetime'] - r['reserve_datetime']).days, axis=1)\n",
    "    data[df] = data[df].groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', 'reserve_visitors']].sum().rename(columns={'visit_datetime':'visit_date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "2eefb47d-8081-4741-8662-6b52235c1f92",
    "_uuid": "e499470cea771207c9cea5543bf3ae8d5b69343e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['tra']['visit_date'] = pd.to_datetime(data['tra']['visit_date'])\n",
    "data['tra']['dow'] = data['tra']['visit_date'].dt.dayofweek\n",
    "data['tra']['year'] = data['tra']['visit_date'].dt.year\n",
    "data['tra']['month'] = data['tra']['visit_date'].dt.month\n",
    "data['tra']['visit_date'] = data['tra']['visit_date'].dt.date\n",
    "\n",
    "data['tes']['visit_date'] = data['tes']['id'].map(lambda x: str(x).split('_')[2])\n",
    "data['tes']['air_store_id'] = data['tes']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n",
    "data['tes']['visit_date'] = pd.to_datetime(data['tes']['visit_date'])\n",
    "data['tes']['dow'] = data['tes']['visit_date'].dt.dayofweek\n",
    "data['tes']['year'] = data['tes']['visit_date'].dt.year\n",
    "data['tes']['month'] = data['tes']['visit_date'].dt.month\n",
    "data['tes']['visit_date'] = data['tes']['visit_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "31b66338-3871-4183-b342-292e64430f4f",
    "_uuid": "50f7dab23a845ef129a48bf31ba5d66bd9327c60",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_stores = data['tes']['air_store_id'].unique()\n",
    "stores = pd.concat([pd.DataFrame({'air_store_id': unique_stores, 'dow': [i]*len(unique_stores)}) for i in range(7)], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].min().rename(columns={'visitors':'min_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) \n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].mean().rename(columns={'visitors':'mean_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].median().rename(columns={'visitors':'median_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].max().rename(columns={'visitors':'max_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].count().rename(columns={'visitors':'count_observations'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "38da6714-9617-481a-a133-560319af5a6f",
    "_uuid": "338259bf538ed869f0b9c7c7e2bc56d496980cfb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stores = pd.merge(stores, data['as'], how='left', on=['air_store_id']) \n",
    "lbl = LabelEncoder()\n",
    "stores['air_genre_name'] = lbl.fit_transform(stores['air_genre_name'])\n",
    "stores['air_area_name'] = lbl.fit_transform(stores['air_area_name'])\n",
    "\n",
    "data['hol']['visit_date'] = pd.to_datetime(data['hol']['visit_date'])\n",
    "data['hol']['day_of_week'] = lbl.fit_transform(data['hol']['day_of_week'])\n",
    "data['hol']['visit_date'] = data['hol']['visit_date'].dt.date\n",
    "train = pd.merge(data['tra'], data['hol'], how='left', on=['visit_date']) \n",
    "test = pd.merge(data['tes'], data['hol'], how='left', on=['visit_date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b40d2db7-d960-4b43-ae5c-5939e68befc4",
    "_uuid": "2010505626053fbae1b852e34c32050cab9599b1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(data['tra'], stores, how='left', on=['air_store_id','dow']) \n",
    "test = pd.merge(data['tes'], stores, how='left', on=['air_store_id','dow'])\n",
    "\n",
    "for df in ['ar','hr']:\n",
    "    train = pd.merge(train, data[df], how='left', on=['air_store_id','visit_date']) \n",
    "    test = pd.merge(test, data[df], how='left', on=['air_store_id','visit_date'])\n",
    "    \n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "6b5bb4d2-197e-4a1e-bd5b-37334c45137d",
    "_uuid": "d57e38ca429843983116df1943e4468b192231bf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RMSLE(y, pred):\n",
    "    return mean_squared_error(y, pred)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "a2194f79-07c5-4184-8396-098ccea92a98",
    "_uuid": "b3d392b9506abc14db46706fe84a86c589e0344f",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>min_visitors</th>\n",
       "      <th>mean_visitors</th>\n",
       "      <th>median_visitors</th>\n",
       "      <th>max_visitors</th>\n",
       "      <th>count_observations</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>reserve_datetime_diff_x</th>\n",
       "      <th>reserve_visitors_x</th>\n",
       "      <th>reserve_datetime_diff_y</th>\n",
       "      <th>reserve_visitors_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.843750</td>\n",
       "      <td>25.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.292308</td>\n",
       "      <td>21.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.738462</td>\n",
       "      <td>35.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.651515</td>\n",
       "      <td>27.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.754386</td>\n",
       "      <td>12.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  visitors  dow  year  month  min_visitors  \\\n",
       "0  air_ba937bf13d40fb24  2016-01-13        25    2  2016      1           7.0   \n",
       "1  air_ba937bf13d40fb24  2016-01-14        32    3  2016      1           2.0   \n",
       "2  air_ba937bf13d40fb24  2016-01-15        29    4  2016      1           4.0   \n",
       "3  air_ba937bf13d40fb24  2016-01-16        22    5  2016      1           6.0   \n",
       "4  air_ba937bf13d40fb24  2016-01-18         6    0  2016      1           2.0   \n",
       "\n",
       "   mean_visitors  median_visitors  max_visitors  count_observations  \\\n",
       "0      23.843750             25.0          57.0                64.0   \n",
       "1      20.292308             21.0          54.0                65.0   \n",
       "2      34.738462             35.0          61.0                65.0   \n",
       "3      27.651515             27.0          53.0                66.0   \n",
       "4      13.754386             12.0          34.0                57.0   \n",
       "\n",
       "   air_genre_name  air_area_name   latitude   longitude  \\\n",
       "0             4.0           62.0  35.658068  139.751599   \n",
       "1             4.0           62.0  35.658068  139.751599   \n",
       "2             4.0           62.0  35.658068  139.751599   \n",
       "3             4.0           62.0  35.658068  139.751599   \n",
       "4             4.0           62.0  35.658068  139.751599   \n",
       "\n",
       "   reserve_datetime_diff_x  reserve_visitors_x  reserve_datetime_diff_y  \\\n",
       "0                     -1.0                -1.0                     -1.0   \n",
       "1                     -1.0                -1.0                     -1.0   \n",
       "2                     -1.0                -1.0                     -1.0   \n",
       "3                     -1.0                -1.0                     -1.0   \n",
       "4                     -1.0                -1.0                     -1.0   \n",
       "\n",
       "   reserve_visitors_y  \n",
       "0                -1.0  \n",
       "1                -1.0  \n",
       "2                -1.0  \n",
       "3                -1.0  \n",
       "4                -1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7f9178b2-e59f-492b-b56f-98ef997dbd09",
    "_uuid": "1a8a720ac5590e1097eb362cb8d0c0f77a201fa8"
   },
   "source": [
    "# **Part 1** \n",
    "## **Visitors as a feature to fit LSTM**\n",
    "\n",
    "Functions from https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4318487b-3c93-47eb-90cd-111fd903392d",
    "_uuid": "e32336ef9ff1a8f4c8fd69e016113325bd24437f"
   },
   "source": [
    "### *Normalize feature*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "efa3fe0a-771e-4d4b-9e57-80d888b1789d",
    "_uuid": "62cddb6514b7153a906a804c40b66da627592525",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.sort_values('visit_date')\n",
    "values = np.log1p(train['visitors'].values).reshape(-1,1)\n",
    "values = values.astype('float32')\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "14290506-1f5e-4fd6-bb25-06ff50a09146",
    "_uuid": "ef66d00ed041acb0f254ae4fa0256274b005d6c3"
   },
   "source": [
    "### *Split into train and test sets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "51cc721e-6f40-4cdc-b03c-27abcb5ce5c7",
    "_uuid": "e0593a65c332c528b40f9faf5c75d72e48e5421d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176475 75633\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(scaled) * 0.7)\n",
    "test_size = len(scaled) - train_size\n",
    "\n",
    "V_train, V_test = scaled[0:train_size,:], scaled[train_size:len(scaled),:]\n",
    "print(len(V_train), len(V_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "01b4dea0-5c79-4145-8d69-dc5ca71cb342",
    "_uuid": "5ea9b627b68aa452bee41448dbcaa9b98d255507"
   },
   "source": [
    "### *Convert an array of values into a dataset matrix*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "c46462f1-6818-4d04-8f39-50b382990393",
    "_uuid": "b1d03dd3506b5c48149f5aed24caa92d06d16465",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        a = dataset[i:(i + look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    print(len(dataY))\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4178114a-7e11-4302-885f-873781cf681b",
    "_uuid": "85ad747825bf1ccf3ec2e87a4f4f76e0b29da18f"
   },
   "source": [
    "### *Create dataset with look back*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "74438c7a-45ea-4ef0-9973-e2d4f7935192",
    "_uuid": "a068488ea3bef9affc7d1052f05bdb719a6383a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176474\n",
      "75632\n"
     ]
    }
   ],
   "source": [
    "look_back = 1\n",
    "trainX, trainY = create_dataset(V_train, look_back)\n",
    "testX, testY = create_dataset(V_test, look_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1cb7592e-fe3d-468d-91d7-9622ff3b9e26",
    "_uuid": "a150742a7687f1a4f70df6b0c45e2c7094037a9c"
   },
   "source": [
    "### *Reshape X for model training*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "7a2e23fa-a184-4f09-be5e-07364b4f902e",
    "_uuid": "c53740ea7194f31e45ca96ac464d79c18a9e9209",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79e6cd0e-2a38-46c6-aa8c-3506fbe177ee",
    "_uuid": "9a5ce2f4b30c1ad5992bd51ad997471682507a91"
   },
   "source": [
    " ### *Train LSTM with 3 epochs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "68511997-bb73-4b3b-96fc-91db08025f4c",
    "_uuid": "f2063c1c8bc8f73d97840e437010d7c8f1760eef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 176474 samples, validate on 75632 samples\n",
      "Epoch 1/3\n",
      "176474/176474 [==============================] - 5s 31us/step - loss: 0.0238 - val_loss: 0.0180\n",
      "Epoch 2/3\n",
      "176474/176474 [==============================] - 4s 25us/step - loss: 0.0176 - val_loss: 0.0180\n",
      "Epoch 3/3\n",
      "176474/176474 [==============================] - 4s 25us/step - loss: 0.0176 - val_loss: 0.0180\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "history = model.fit(trainX, trainY, epochs=3, batch_size=100,\n",
    "                            validation_data=(testX, testY), verbose=1, shuffle=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1e135933-aefb-482f-991c-fae28736125e",
    "_uuid": "7b9a6cd42e0d82b105dd1244a06588a899014d3f"
   },
   "source": [
    "### *Make prediction and apply invert scaling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "6bac9566-3ce3-45cd-9de3-680220c418b6",
    "_uuid": "0e66c5594b0f96320d29ed724d32e052d953c059",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yhat = model.predict(testX)\n",
    "\n",
    "yhat_inverse = scaler.inverse_transform(yhat.reshape(-1, 1))\n",
    "testY_inverse = scaler.inverse_transform(testY.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3d2cdd33-4cb1-4776-b5cc-9b8ab4829401",
    "_uuid": "ef8133a54f36a3e21370c1e636a94918aaa9513b"
   },
   "source": [
    "### *RMSLE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "4d9d99f7-8f52-4518-9e39-f9306759e466",
    "_uuid": "d7a0a497c8430e36cc97a075df0312ea8660a27c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSLE: 0.816\n"
     ]
    }
   ],
   "source": [
    "rmsle = RMSLE(testY_inverse, yhat_inverse)\n",
    "print('Test RMSLE: %.3f' % rmsle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "addf84e4-7235-4ca6-b8a9-f631ade22fc1",
    "_uuid": "00ef42aef7ecc896c47423ad1190116fc0345f13"
   },
   "source": [
    "# **Part 2**\n",
    "## **Multivariate Forecast**\n",
    "\n",
    "Functions from https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "38878ce6-98da-406d-ab3d-c5bee4e1d238",
    "_uuid": "c48e420633e0bf91cde66d03ac57eafcf229a783"
   },
   "source": [
    "### *Using all features for model training*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "6d7d4fc4-3526-47f2-9069-2783e7c43ff8",
    "_uuid": "f8264be6aa6785f04a87a4ca8155281c840c7bdd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>min_visitors</th>\n",
       "      <th>mean_visitors</th>\n",
       "      <th>median_visitors</th>\n",
       "      <th>max_visitors</th>\n",
       "      <th>count_observations</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>reserve_datetime_diff_x</th>\n",
       "      <th>reserve_visitors_x</th>\n",
       "      <th>reserve_datetime_diff_y</th>\n",
       "      <th>reserve_visitors_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.382353</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.581941</td>\n",
       "      <td>130.348436</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.656716</td>\n",
       "      <td>18.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>35.693840</td>\n",
       "      <td>139.703549</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>41.855072</td>\n",
       "      <td>41.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>35.735623</td>\n",
       "      <td>139.651658</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.322034</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>34.766093</td>\n",
       "      <td>135.628100</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>32.985507</td>\n",
       "      <td>31.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.737597</td>\n",
       "      <td>135.341564</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dow  year  month  min_visitors  mean_visitors  median_visitors  \\\n",
       "visit_date                                                                   \n",
       "2016-01-01    4  2016      1           2.0      10.382353             10.0   \n",
       "2016-01-01    4  2016      1           3.0      18.656716             18.0   \n",
       "2016-01-01    4  2016      1          10.0      41.855072             41.0   \n",
       "2016-01-01    4  2016      1           1.0       4.322034              3.0   \n",
       "2016-01-01    4  2016      1          15.0      32.985507             31.0   \n",
       "\n",
       "            max_visitors  count_observations  air_genre_name  air_area_name  \\\n",
       "visit_date                                                                    \n",
       "2016-01-01          20.0                68.0             2.0            3.0   \n",
       "2016-01-01          48.0                67.0             2.0           77.0   \n",
       "2016-01-01          83.0                69.0             7.0           66.0   \n",
       "2016-01-01          13.0                59.0             1.0           92.0   \n",
       "2016-01-01          71.0                69.0             6.0           30.0   \n",
       "\n",
       "             latitude   longitude  reserve_datetime_diff_x  \\\n",
       "visit_date                                                   \n",
       "2016-01-01  33.581941  130.348436                     -1.0   \n",
       "2016-01-01  35.693840  139.703549                     -1.0   \n",
       "2016-01-01  35.735623  139.651658                     -1.0   \n",
       "2016-01-01  34.766093  135.628100                     -1.0   \n",
       "2016-01-01  34.737597  135.341564                     -1.0   \n",
       "\n",
       "            reserve_visitors_x  reserve_datetime_diff_y  reserve_visitors_y  \n",
       "visit_date                                                                   \n",
       "2016-01-01                -1.0                     -1.0                -1.0  \n",
       "2016-01-01                -1.0                     -1.0                -1.0  \n",
       "2016-01-01                -1.0                     -1.0                -1.0  \n",
       "2016-01-01                -1.0                     -1.0                -1.0  \n",
       "2016-01-01                -1.0                     -1.0                -1.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.sort_values('visit_date')\n",
    "target_train = np.log1p(train['visitors'].values)\n",
    "\n",
    "col = [c for c in train if c not in ['id', 'air_store_id', 'visitors']]\n",
    "\n",
    "train = train[col]\n",
    "train.set_index('visit_date', inplace=True)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7b4fa080-c750-43fd-ab31-2dafb71ef0ed",
    "_uuid": "22a7e3a4b35aba652f9e500675707d4561e4aa83"
   },
   "source": [
    "### *Function to convert series to supervised learning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "1ebfdd4c-24ad-4280-bbe7-63234d71bfc7",
    "_uuid": "1690ee4ad571a4978b358daa6f9cbbb4be41fcd9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # Input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # Forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # Put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # Drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "64f79c05-b4aa-46a1-9efd-69db23447f48",
    "_uuid": "dfb94265d258324c6cd183826da54afbfa89171d"
   },
   "source": [
    "### *Normalize features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "c4e4f56e-9f43-4ca2-88a8-28f7f22ec7ed",
    "_uuid": "2b2b4c58989fd03bade2c8bd227602a1c8d7a5da",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['visitors'] = target_train\n",
    "values = train.values\n",
    "values = values.astype('float32')\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a71d31a6-b169-4a2b-9b50-849bf3c34f24",
    "_uuid": "3ca96959d0de395f6df36b4113e9f9762c0fa4d6"
   },
   "source": [
    "### *Frame as supervised learning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "a0c1f374-dad5-42fe-a33f-874b951e934e",
    "_uuid": "e49faf36f97ff0bd128a1fa9fb2549b3d454b42b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var9(t-1)</th>\n",
       "      <th>var10(t-1)</th>\n",
       "      <th>...</th>\n",
       "      <th>var8(t)</th>\n",
       "      <th>var9(t)</th>\n",
       "      <th>var10(t)</th>\n",
       "      <th>var11(t)</th>\n",
       "      <th>var12(t)</th>\n",
       "      <th>var13(t)</th>\n",
       "      <th>var14(t)</th>\n",
       "      <th>var15(t)</th>\n",
       "      <th>var16(t)</th>\n",
       "      <th>var17(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022556</td>\n",
       "      <td>0.076686</td>\n",
       "      <td>0.071895</td>\n",
       "      <td>0.023918</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.038835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.757282</td>\n",
       "      <td>0.815045</td>\n",
       "      <td>0.968543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030075</td>\n",
       "      <td>0.132432</td>\n",
       "      <td>0.124183</td>\n",
       "      <td>0.055809</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.757282</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.650485</td>\n",
       "      <td>0.815973</td>\n",
       "      <td>0.968186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.280179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082707</td>\n",
       "      <td>0.288725</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.095672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.650485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.794438</td>\n",
       "      <td>0.940490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015038</td>\n",
       "      <td>0.035856</td>\n",
       "      <td>0.026144</td>\n",
       "      <td>0.015945</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.300971</td>\n",
       "      <td>0.793805</td>\n",
       "      <td>0.938517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.351724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120301</td>\n",
       "      <td>0.228969</td>\n",
       "      <td>0.209150</td>\n",
       "      <td>0.082005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.300971</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.844660</td>\n",
       "      <td>0.815762</td>\n",
       "      <td>0.968633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
       "1   0.666667        0.0        0.0   0.022556   0.076686   0.071895   \n",
       "2   0.666667        0.0        0.0   0.030075   0.132432   0.124183   \n",
       "3   0.666667        0.0        0.0   0.082707   0.288725   0.274510   \n",
       "4   0.666667        0.0        0.0   0.015038   0.035856   0.026144   \n",
       "5   0.666667        0.0        0.0   0.120301   0.228969   0.209150   \n",
       "\n",
       "   var7(t-1)  var8(t-1)  var9(t-1)  var10(t-1)    ...      var8(t)   var9(t)  \\\n",
       "1   0.023918   0.985714   0.214286    0.038835    ...     0.971429  0.214286   \n",
       "2   0.055809   0.971429   0.214286    0.757282    ...     1.000000  0.571429   \n",
       "3   0.095672   1.000000   0.571429    0.650485    ...     0.857143  0.142857   \n",
       "4   0.015945   0.857143   0.142857    0.902913    ...     1.000000  0.500000   \n",
       "5   0.082005   1.000000   0.500000    0.300971    ...     1.000000  0.142857   \n",
       "\n",
       "   var10(t)  var11(t)  var12(t)  var13(t)  var14(t)  var15(t)  var16(t)  \\\n",
       "1  0.757282  0.815045  0.968543       0.0       0.0       0.0       0.0   \n",
       "2  0.650485  0.815973  0.968186       0.0       0.0       0.0       0.0   \n",
       "3  0.902913  0.794438  0.940490       0.0       0.0       0.0       0.0   \n",
       "4  0.300971  0.793805  0.938517       0.0       0.0       0.0       0.0   \n",
       "5  0.844660  0.815762  0.968633       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   var17(t)  \n",
       "1  0.465644  \n",
       "2  0.280179  \n",
       "3  0.205894  \n",
       "4  0.351724  \n",
       "5  0.150594  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "reframed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4527e2c0-c138-4d8a-a446-4927973ed61d",
    "_uuid": "23891f7fb6d0b1362b463c945ade07c6d70c2403"
   },
   "source": [
    "### *Drop unncessary columns*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "283d2ccc-bb49-4cba-aa6f-8cc4eb220f91",
    "_uuid": "a98b0b425675269218b81e9a27215996a0678b43",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var9(t-1)</th>\n",
       "      <th>var10(t-1)</th>\n",
       "      <th>var11(t-1)</th>\n",
       "      <th>var12(t-1)</th>\n",
       "      <th>var13(t-1)</th>\n",
       "      <th>var14(t-1)</th>\n",
       "      <th>var15(t-1)</th>\n",
       "      <th>var16(t-1)</th>\n",
       "      <th>var17(t-1)</th>\n",
       "      <th>var17(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022556</td>\n",
       "      <td>0.076686</td>\n",
       "      <td>0.071895</td>\n",
       "      <td>0.023918</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.038835</td>\n",
       "      <td>0.768135</td>\n",
       "      <td>0.904147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.378435</td>\n",
       "      <td>0.465644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030075</td>\n",
       "      <td>0.132432</td>\n",
       "      <td>0.124183</td>\n",
       "      <td>0.055809</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.757282</td>\n",
       "      <td>0.815045</td>\n",
       "      <td>0.968543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465644</td>\n",
       "      <td>0.280179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082707</td>\n",
       "      <td>0.288725</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.095672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.650485</td>\n",
       "      <td>0.815973</td>\n",
       "      <td>0.968186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.280179</td>\n",
       "      <td>0.205894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015038</td>\n",
       "      <td>0.035856</td>\n",
       "      <td>0.026144</td>\n",
       "      <td>0.015945</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.794438</td>\n",
       "      <td>0.940490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205894</td>\n",
       "      <td>0.351724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120301</td>\n",
       "      <td>0.228969</td>\n",
       "      <td>0.209150</td>\n",
       "      <td>0.082005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.300971</td>\n",
       "      <td>0.793805</td>\n",
       "      <td>0.938517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.351724</td>\n",
       "      <td>0.150594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
       "1   0.666667        0.0        0.0   0.022556   0.076686   0.071895   \n",
       "2   0.666667        0.0        0.0   0.030075   0.132432   0.124183   \n",
       "3   0.666667        0.0        0.0   0.082707   0.288725   0.274510   \n",
       "4   0.666667        0.0        0.0   0.015038   0.035856   0.026144   \n",
       "5   0.666667        0.0        0.0   0.120301   0.228969   0.209150   \n",
       "\n",
       "   var7(t-1)  var8(t-1)  var9(t-1)  var10(t-1)  var11(t-1)  var12(t-1)  \\\n",
       "1   0.023918   0.985714   0.214286    0.038835    0.768135    0.904147   \n",
       "2   0.055809   0.971429   0.214286    0.757282    0.815045    0.968543   \n",
       "3   0.095672   1.000000   0.571429    0.650485    0.815973    0.968186   \n",
       "4   0.015945   0.857143   0.142857    0.902913    0.794438    0.940490   \n",
       "5   0.082005   1.000000   0.500000    0.300971    0.793805    0.938517   \n",
       "\n",
       "   var13(t-1)  var14(t-1)  var15(t-1)  var16(t-1)  var17(t-1)  var17(t)  \n",
       "1         0.0         0.0         0.0         0.0    0.378435  0.465644  \n",
       "2         0.0         0.0         0.0         0.0    0.465644  0.280179  \n",
       "3         0.0         0.0         0.0         0.0    0.280179  0.205894  \n",
       "4         0.0         0.0         0.0         0.0    0.205894  0.351724  \n",
       "5         0.0         0.0         0.0         0.0    0.351724  0.150594  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed.drop(reframed.columns[[i for i in range(17,33)]], axis=1, inplace=True)\n",
    "reframed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "01e41387-5d43-4bc3-8399-07888fa69acd",
    "_uuid": "9fdd0ba18aa6c252248ea216ee339988669515f4"
   },
   "source": [
    "### *Split into train and test sets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "b79a3851-b0c5-4a0c-acaa-9436ed229439",
    "_uuid": "c9dea01c0946587f54f6fdd0d2049bed41f0a907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176474, 1, 17) (176474,) (75633, 1, 17) (75633,)\n"
     ]
    }
   ],
   "source": [
    "values = reframed.values\n",
    "n_train_days = int(len(values) * 0.7)\n",
    "train = values[:n_train_days, :]\n",
    "test = values[n_train_days:, :]\n",
    "# Split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# Reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9b37acff-e975-4c11-914a-9b8b090747ca",
    "_uuid": "ba44e1fad5384246cc42831740c9e50b39322856"
   },
   "source": [
    " ### *Train LSTM with 3 epochs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "67593e30-d79a-469a-b373-387cd5bafe39",
    "_uuid": "ab4349824bd3859cfb232e6e46de90fad4b42f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 176474 samples, validate on 75633 samples\n",
      "Epoch 1/3\n",
      "176474/176474 [==============================] - 5s 31us/step - loss: 0.0216 - val_loss: 0.0178\n",
      "Epoch 2/3\n",
      "176474/176474 [==============================] - 4s 24us/step - loss: 0.0172 - val_loss: 0.0177\n",
      "Epoch 3/3\n",
      "176474/176474 [==============================] - 4s 24us/step - loss: 0.0171 - val_loss: 0.0177\n"
     ]
    }
   ],
   "source": [
    "multi_model = Sequential()\n",
    "multi_model.add(LSTM(4, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "multi_model.add(Dense(1))\n",
    "multi_model.compile(loss='mse', optimizer='adam')\n",
    "multi_history = multi_model.fit(train_X, train_y, epochs=3,\n",
    "                                batch_size=100, validation_data=(test_X, test_y),\n",
    "                                verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ff2f075c-b0b9-4c3f-9587-83dd613d6e3f",
    "_uuid": "ba033e07a4b21b9b89f493dc23924d4999afe150"
   },
   "source": [
    "### *Make prediction*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "a106cb5a-a304-4939-9642-8924cba32273",
    "_uuid": "9bc02f954b5a61e508067f3cf9604d68182dde49",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yhat = multi_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f3a9ab8f-1fff-4b70-876e-ec83a0dca450",
    "_uuid": "0a6ed5c118a4a723152ec0674d8687567f697cf7"
   },
   "source": [
    "### *Apply invert scaling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "abd97ae2-7c9c-48b2-ac5b-46a1ad3f1c10",
    "_uuid": "279fb937c1d1462df8e3be8bea5aa4d6a8fb6017",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# Invert scaling for forecast\n",
    "inv_yhat = np.concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# Invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = np.concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8a67ef42-bc43-4453-bf5a-75bddcec54a0",
    "_uuid": "8c39ade35c980876f0aa094916a524571bc974cb"
   },
   "source": [
    "### *RMSLE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "2e87a7ba-1b8d-496e-a5ee-cc64d25f8187",
    "_uuid": "7781a4c953d7159899c1d2a1a77e9d55c7c1b8b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSLE: 0.798\n"
     ]
    }
   ],
   "source": [
    "rmsle = RMSLE(inv_y, inv_yhat)\n",
    "print('Test RMSLE: %.3f' % rmsle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slight improve, not enough, however, to beat benchmarks. I would add that the LSTM may not be suited for autoregression type problems (at least with such set of features, window and LSTM-configuration) and that maybe better off exploring an MLP with a large window. But i think it's good demo how to fit neural network to a multivariate time series forecasting problem. \n",
    "Specifically:\n",
    "\n",
    "* How to transform a raw dataset into something we can use for time series forecasting.\n",
    "* How to prepare data and fit an LSTM for a multivariate time series forecasting problem.\n",
    "* How to make a forecast and rescale the result back into the original units."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
