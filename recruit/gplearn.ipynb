{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "#See example in http://nbviewer.jupyter.org/github/trevorstephens/gplearn/blob/master/doc/gp_examples.ipynb\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "tcurrent   = start_time\n",
    "\n",
    "np.random.seed(1234)   \n",
    "\n",
    "data = {\n",
    "    'tra':   pd.read_csv('input/air_visit_data.csv'),\n",
    "    'as':    pd.read_csv('input/air_store_info.csv'),\n",
    "    'hs':    pd.read_csv('input/hpg_store_info.csv'),\n",
    "    'ar':    pd.read_csv('input/air_reserve.csv'),\n",
    "    'hr':    pd.read_csv('input/hpg_reserve.csv'),\n",
    "    'id':    pd.read_csv('input/store_id_relation.csv'),\n",
    "    'tes':   pd.read_csv('input/sample_submission.csv'),\n",
    "    'hol':   pd.read_csv('input/date_info.csv').rename(columns={'calendar_date': 'visit_date' })\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])\n",
    "\n",
    "for df in ['ar', 'hr']:\n",
    "    data[df]['visit_datetime']   = pd.to_datetime(data[df]['visit_datetime'])\n",
    "    data[df]['visit_datetime']   = data[df]['visit_datetime'].dt.date\n",
    "    data[df]['reserve_datetime'] = pd.to_datetime(data[df]['reserve_datetime'])\n",
    "    data[df]['reserve_datetime'] = data[df]['reserve_datetime'].dt.date\n",
    "    data[df]['reserve_datetime_diff'] = data[df].apply(\n",
    "        lambda r: (r['visit_datetime'] - r['reserve_datetime']).days, axis=1)\n",
    "        \n",
    "    #--- begin  new features    \n",
    "    data[df]['reserve_datetime_diff_2'] = data[df].apply(\n",
    "        lambda r: ( (r['visit_datetime'] - r['reserve_datetime']).days)**2.1, axis=1)\n",
    "    data[df]['reserve_datetime_diff_3'] = data[df].apply(\n",
    "        lambda r: ( (r['visit_datetime'] - r['reserve_datetime']).days)**3.2, axis=1)\n",
    "    #--- end new features        \n",
    "        \n",
    "    data[df] = data[df].groupby(\n",
    "        ['air_store_id', 'visit_datetime'], as_index=False)[[\n",
    "            'reserve_datetime_diff', 'reserve_visitors'\n",
    "        ]].sum().rename(columns={\n",
    "            'visit_datetime': 'visit_date'\n",
    "        })\n",
    "        \n",
    "    show_data = 0    \n",
    "    if (show_data==1):\n",
    "        print(data[df].head())\n",
    "\n",
    "data['tra']['visit_date'] = pd.to_datetime(data['tra']['visit_date'])\n",
    "data['tra']['dow']        = data['tra']['visit_date'].dt.dayofweek\n",
    "data['tra']['year']       = data['tra']['visit_date'].dt.year\n",
    "data['tra']['month']      = data['tra']['visit_date'].dt.month\n",
    "data['tra']['visit_date'] = data['tra']['visit_date'].dt.date\n",
    "\n",
    "data['tes']['visit_date'] = data['tes']['id'].map(\n",
    "    lambda x: str(x).split('_')[2])\n",
    "data['tes']['air_store_id'] = data['tes']['id'].map(\n",
    "    lambda x: '_'.join(x.split('_')[:2]))\n",
    "data['tes']['visit_date'] = pd.to_datetime(data['tes']['visit_date'])\n",
    "data['tes']['dow'] = data['tes']['visit_date'].dt.dayofweek\n",
    "data['tes']['year'] = data['tes']['visit_date'].dt.year\n",
    "data['tes']['month'] = data['tes']['visit_date'].dt.month\n",
    "data['tes']['visit_date'] = data['tes']['visit_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_stores = data['tes']['air_store_id'].unique()\n",
    "stores = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame({\n",
    "            'air_store_id': unique_stores,\n",
    "            'dow': [i] * len(unique_stores)\n",
    "        }) for i in range(7)\n",
    "    ],\n",
    "    axis=0,\n",
    "    ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "#sure it can be compressed...\n",
    "tmp = data['tra'].groupby(\n",
    "    ['air_store_id', 'dow'],\n",
    "    as_index=False)['visitors'].min().rename(columns={\n",
    "        'visitors': 'min_visitors'\n",
    "    })\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'dow'])\n",
    "tmp = data['tra'].groupby(\n",
    "    ['air_store_id', 'dow'],\n",
    "    as_index=False)['visitors'].mean().rename(columns={\n",
    "        'visitors': 'mean_visitors'\n",
    "    })\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'dow'])\n",
    "tmp = data['tra'].groupby(\n",
    "    ['air_store_id', 'dow'],\n",
    "    as_index=False)['visitors'].median().rename(columns={\n",
    "        'visitors': 'median_visitors'\n",
    "    })\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'dow'])\n",
    "tmp = data['tra'].groupby(\n",
    "    ['air_store_id', 'dow'],\n",
    "    as_index=False)['visitors'].max().rename(columns={\n",
    "        'visitors': 'max_visitors'\n",
    "    })\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'dow'])\n",
    "tmp = data['tra'].groupby(\n",
    "    ['air_store_id', 'dow'],\n",
    "    as_index=False)['visitors'].count().rename(columns={\n",
    "        'visitors': 'count_observations'\n",
    "    })\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'dow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stores = pd.merge(stores, data['as'], how='left', on=['air_store_id'])\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "stores['air_genre_name'] = lbl.fit_transform(stores['air_genre_name'])\n",
    "stores['air_area_name'] = lbl.fit_transform(stores['air_area_name'])\n",
    "\n",
    "data['hol']['visit_date'] = pd.to_datetime(data['hol']['visit_date'])\n",
    "data['hol']['day_of_week'] = lbl.fit_transform(data['hol']['day_of_week'])\n",
    "data['hol']['visit_date'] = data['hol']['visit_date'].dt.date\n",
    "\n",
    "train = pd.merge(data['tra'], data['hol'], how='left', on=['visit_date'])\n",
    "test = pd.merge(data['tes'], data['hol'], how='left', on=['visit_date'])\n",
    "\n",
    "train = pd.merge(data['tra'], stores, how='left', on=['air_store_id', 'dow'])\n",
    "test = pd.merge(data['tes'], stores, how='left', on=['air_store_id', 'dow'])\n",
    "\n",
    "for df in ['ar', 'hr']:\n",
    "    train = pd.merge(\n",
    "        train, data[df], how='left', on=['air_store_id', 'visit_date'])\n",
    "    test = pd.merge(\n",
    "        test, data[df], how='left', on=['air_store_id', 'visit_date'])\n",
    "\n",
    "col = [\n",
    "    c for c in train\n",
    "    if c not in ['id', 'air_store_id', 'visit_date', 'visitors']\n",
    "]\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c, dtype in zip(train.columns, train.dtypes):\n",
    "    if dtype == np.float64:\n",
    "        train[c] = train[c].astype(np.float32)\n",
    "\n",
    "for c, dtype in zip(test.columns, test.dtypes):\n",
    "    if dtype == np.float64:\n",
    "        test[c] = test[c].astype(np.float32)\n",
    "\n",
    "train_x = train.drop(['air_store_id', 'visit_date', 'visitors'], axis=1)\n",
    "train_y = np.log1p(train['visitors'].values)\n",
    "\n",
    "if (show_data==1):\n",
    "    print(train_x.shape, train_y.shape)\n",
    "    \n",
    "test_x  = test.drop(['id', 'air_store_id', 'visit_date', 'visitors'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Adopted regressor =  4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "regressor = 4\n",
    "\n",
    "print('\\n\\nAdopted regressor = ', regressor,'\\n')\n",
    "\n",
    "if (regressor == 1):\n",
    "    print('Starting XGBoost')\n",
    "    boost_params = {'eval_metric': 'rmse'}\n",
    "    xgb0 = xgb.XGBRegressor(\n",
    "        max_depth        = 8,\n",
    "        learning_rate    = 0.01,\n",
    "        n_estimators     = 10000,\n",
    "        objective        = 'reg:linear',\n",
    "        gamma            = 0,\n",
    "        min_child_weight = 1,\n",
    "        subsample        = 1,\n",
    "        colsample_bytree = 1,\n",
    "        scale_pos_weight = 1,\n",
    "        seed             = 27,\n",
    "        **boost_params)\n",
    "        \n",
    "    xgb0.fit(train_x, train_y)\n",
    "    predict_y = xgb0.predict(test_x)\n",
    "    print('Finished XGBoost')\n",
    "    \n",
    "    \n",
    "if (regressor == 2):    \n",
    "    print('Starting Extra trees')\n",
    "    et = ExtraTreesRegressor (n_estimators         = 10000, \n",
    "                                 max_depth         = 8, \n",
    "                                 n_jobs            = -1, \n",
    "                                 random_state      = 11, \n",
    "                                 verbose           = 0, \n",
    "                                 warm_start        = True,\n",
    "                                 min_samples_leaf  = 120, \n",
    "                                 max_features      = 0.8)    \n",
    "    et.fit(train_x, train_y)\n",
    "    predict_y = et.predict(test_x)\n",
    "    print('Finished Extra trees')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Genetic Programming\n",
      "    |    Population Average   |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0   405.46    2862704645.31        2   0.581068049643   0.575271763408    548.03m\n",
      "   1    96.57    208.911352395        2   0.579387358561   0.590331051658    346.39m\n",
      "   2      9.7    162.785674983        2   0.579329968907   0.590837736395    241.13m\n",
      "   3     3.49    23.3025837326        2   0.578978245865   0.593932514375    186.37m\n",
      "   4     2.78     65.787448749        2   0.579187688739   0.592091820966    153.25m\n",
      "   5     2.73    12.3187149265        2   0.579375149217   0.590438886761    131.15m\n",
      "   6     4.32    3064.66896666        2   0.579126151504   0.592633304568    115.69m\n",
      "   7     2.24    98.9883109355        2   0.579152213935   0.592404041283    103.78m\n",
      "   8     3.17    223.788266727        2   0.579085797335   0.592988092714     94.57m\n",
      "   9     2.69    106.644086662        2   0.578087477328   0.601690825539     87.13m\n",
      "  10     2.52    197.292803169        2   0.579024924073   0.593522833856     80.97m\n",
      "  11     3.87    130.940048657        2   0.578844959067   0.595100598489     76.02m\n",
      "  12     3.36    33.1658864566        2   0.579113519293    0.59274439067     71.96m\n",
      "  13      2.9    1057.48602936        2   0.579137108299   0.592536933033     68.29m\n",
      "  14     6.85     75.051081737        2   0.579184823258   0.592117047423     65.44m\n",
      "  15     2.39    19.0850469197        2   0.579261152763   0.591444665535     62.53m\n",
      "  16     2.76    2417.11799218        2   0.579225641892   0.591757584659     60.00m\n",
      "  17     3.39    208.872531318        2    0.57890197931   0.594601204549     57.76m\n",
      "  18     2.62    30.8899603988        2   0.579188752112    0.59208245919     55.71m\n",
      "  19     2.58    28.3983788077        2   0.579453014543     0.5897507892     53.85m\n",
      "  20     2.77     134.52801914        2   0.578692383896   0.596434582694     52.18m\n",
      "  21     4.04    3757.72468753        2   0.578463735484    0.59842746229     50.77m\n",
      "  22     3.29    1040.81875887        2   0.579190418817   0.592067785433     49.41m\n",
      "  23     5.37    743.190446632        2   0.579216961954   0.591834043543     48.32m\n",
      "  24     8.68    113.861663773        2   0.579311904596   0.590997123251     47.40m\n",
      "  25     2.68    6.30290670078        2   0.579216227411   0.591840513394     46.26m\n",
      "  26     4.28    16461.9350278        2   0.579142762363   0.592487195335     45.28m\n",
      "  27     2.78    45.1761545181        2   0.579414565958   0.590090672011     44.34m\n",
      "  28     3.13    2882.28910869        2   0.579169528277    0.59225167751     43.42m\n",
      "  29     2.57    168.827849093        2   0.579421758823   0.590027104191     42.56m\n",
      "  30      2.3    49.9767727716        2   0.578835407196   0.595184209776     41.73m\n",
      "  31     2.69    1831.14210436        2    0.57880989015   0.595407506179     40.97m\n",
      "  32      4.4    159.901511533        2   0.579147108906   0.592448956469     40.32m\n",
      "  33     2.76    16666.5766989        2   0.578763476841   0.595813423355     39.64m\n",
      "  34     2.56    29.8760692361        2   0.578990298658   0.593826760886     38.99m\n",
      "  35     2.91      117.5594321        2   0.579426590624    0.58998439827     38.41m\n",
      "  36      4.8    12.1710389651        2   0.579000150125   0.593740306618     37.91m\n",
      "  37     3.62    166.924376538        2    0.57944207414   0.589847523834     37.35m\n",
      "  38     3.38    61.0646440956        2   0.579592158423   0.588518937477     36.87m\n",
      "  39     2.97    6611.16345638        2   0.579522541356   0.589135621788     36.43m\n",
      "  40     3.88    2845.35244849        2   0.579055278664    0.59325625124     35.98m\n",
      "  41     2.82    10.1074738088        2   0.579219454271   0.591812090623     35.53m\n",
      "  42      2.3    11.1913983395        2   0.579100538238   0.592858520259     35.08m\n",
      "  43     3.82    1198.03343744        2   0.578938728484   0.594279099936     34.66m\n",
      "  44     2.95    68.6993266285        2   0.578871730539   0.594866187271     34.24m\n",
      "  45     3.35    35.1310709504        2   0.579253750573   0.591509908317     33.86m\n",
      "  46     3.92    179.864812552        2   0.579562580515   0.588781033491     33.53m\n",
      "  47     5.01     365.41573303        7   0.560017126607   0.567320569312     33.29m\n",
      "  48     3.69    4.13337858183        7    0.55988714447   0.568474031746     32.97m\n",
      "  49     6.96    30.5689666581        8    0.55561848104   0.554741990517     32.75m\n",
      "  50     8.08    88.5604123427        8   0.554824673756   0.561846871392     32.56m\n",
      "  51     7.48     6.4451772481       11   0.554380841899   0.560560984156     32.31m\n",
      "  52    11.39    95546.6130699       11   0.554216869257   0.562018344715     32.13m\n",
      "  53    11.65    1067.51526679       13   0.553908794564   0.564745130104     31.97m\n",
      "  54    10.71    84.0747954534       13   0.553898838246   0.564833009186     31.79m\n",
      "  55    11.67    22.5937954985       13   0.554082541016     0.5612668724     31.64m\n",
      "  56    14.52    109.078188569       11   0.553564414991   0.567775969974     31.55m\n",
      "  57    12.63    2.13586059139       22   0.554103322022   0.559931057322     31.41m\n",
      "  58    10.79    3.33434495127       11   0.553919737921   0.564648521358     31.24m\n",
      "  59     10.8    2.56451754687       14   0.553941037561    0.56169384246     31.06m\n",
      "  60    11.79    3.13513823065       14   0.553991061046    0.56124965339     30.91m\n",
      "  61    13.02    5.87497738892       15   0.553092163913   0.553703142695     30.78m\n",
      "  62    12.59    2.41226446954       22   0.547565054404   0.547357302488     30.64m\n",
      "  63    13.05    94.5111157901       22   0.546913060222   0.553504471181     30.51m\n",
      "  64    17.83    25.0058217517       22   0.546398777996   0.546674304859     30.45m\n",
      "  65    22.32    1.76281024443       26   0.543187122999   0.550045031948     30.46m\n",
      "  66    22.03     2.7691564107       28   0.525949835712   0.527722089642     30.46m\n",
      "  67    24.02    2.29011793628       25   0.525576934977   0.531055184265     30.52m\n",
      "  68    27.49    1.19826565857       28   0.524859864385   0.528152715205     30.65m\n",
      "  69    24.91    1.40394871507       28   0.524412430524   0.532137738669     30.69m\n",
      "  70    24.92    3.11464459306       28   0.522828752796   0.526368627482     30.71m\n",
      "  71    27.86    3.08634565825       29   0.522684245739   0.527840942967     30.79m\n",
      "  72    26.59    1.98473238501       49   0.522243741445   0.531750582461     30.87m\n",
      "  73     28.0    37.4098530195       49    0.52261170565    0.52848697979     30.94m\n",
      "  74    24.38    1.75862820376       32   0.522464059972   0.528943269579     30.95m\n",
      "  75    22.78    1.54422848079       39   0.521928644444   0.533679299503     30.96m\n",
      "  76    25.72    1.69781274328       23   0.522599548865   0.527305848105     30.99m\n",
      "  77    21.73    1.17530767075       21   0.522359057985   0.530730206107     30.99m\n",
      "  78    20.55    1.48715280617       21   0.522472102362   0.529727807896     30.97m\n",
      "  79     22.5    10.0404722736       23    0.52239286921   0.530430613174     31.03m\n",
      "  80    19.49    2.35548664378       29   0.522395421605   0.530407989378     31.02m\n",
      "  81     22.0    1.67350808169       29   0.522228315198    0.53193197872     30.98m\n",
      "  82    20.55    4.45372746765       34   0.522657119549   0.528082629878     30.90m\n",
      "  83    20.95    3.04191408343       21   0.522562370387   0.528925854121     30.84m\n",
      "  84    21.44    10.5312828528       21   0.522357242358   0.530746288598     30.80m\n",
      "  85     20.1    1.41317057734       21   0.522710262391   0.527609025929     30.75m\n",
      "  86    20.81    1.35037443203       21   0.522352354349   0.530789582988     30.69m\n",
      "  87    19.36    3.02283730067       27    0.52217050172   0.532397510688     30.60m\n",
      "  88    23.01    1.29504829569       25   0.522289410247   0.532375002859     30.56m\n",
      "  89     22.1    1.30892585586       27   0.522220563799   0.531955406064     30.50m\n",
      "  90    21.29    2.97010819939       38   0.522398853784   0.527535371582     30.43m\n",
      "  91    22.72    3.59348150222       21   0.522364559673   0.533598425517     30.37m\n",
      "  92    21.59    2.22034110562       37   0.522829148121   0.529487538986     30.32m\n",
      "  93    21.52    8093.85063957       21   0.522666206882    0.52736163691     30.26m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  94    23.18    1.52804126246       20   0.522715484165   0.526740035344     30.20m\n",
      "  95    20.07    6341.41694445       20   0.522192323491   0.524970884042     30.11m\n",
      "  96    19.62    1.70543580708       20   0.522143558902   0.534090335394     30.03m\n",
      "  97    18.68    1.19490212945       34   0.521676019136   0.527601260648     29.94m\n",
      "  98    19.29     10.250513628       23   0.521472754607   0.531349434257     29.88m\n",
      "  99    21.86    2.12709034728       48   0.521344459283   0.529407421941     29.84m\n",
      " 100     18.9     2.9747097936       17   0.521626955307    0.52998548442     29.76m\n",
      " 101    17.79    1.48844840276       35   0.521033719136   0.521755355946     29.67m\n",
      " 102    18.05    2.10350433744       23   0.521592926313   0.523888601133     29.58m\n",
      " 103     19.8    1.89670464712       23   0.521355031738   0.526015448116     29.50m\n",
      " 104    18.55    10.2960089645       19   0.520763551731   0.531262396113     29.41m\n",
      " 105     19.8    1.74581210719       23   0.521242052397   0.526540091467     29.34m\n",
      " 106    19.27    10.0853750328       23   0.521086540461   0.527923579604     29.25m\n",
      " 107    18.24    18.2418885705       19   0.520985121628     0.5293036657     29.15m\n",
      " 108    18.66    11.7550660055       19   0.521235991151   0.522431583032     29.05m\n",
      " 109    19.68    24.5490698765       21   0.521213838824   0.524714924664     28.97m\n",
      " 110    18.58    251.381279154       19   0.520737303512   0.526888309369     28.87m\n",
      " 111    19.53    606703.926474       19   0.520646100797   0.527698849687     28.78m\n",
      " 112    17.59    6.60001949421       23   0.521045377671   0.524140056758     28.67m\n",
      " 113    18.08    186.254243365       19   0.520264772419   0.524391223212     28.57m\n",
      " 114    19.77    7.02737601431       19   0.520468995375   0.529268878258     28.48m\n",
      " 115    18.22    12.1805450566       23   0.519751413374   0.528952954496     28.39m\n",
      " 116    21.96    1.81333931176       19    0.51994906213    0.52720184448     28.32m\n",
      " 117    19.25    4.71483568004       19   0.520410720555    0.52793322597     28.23m\n",
      " 118    17.73    29.2068738398       19   0.519998330267   0.526764332938     28.13m\n",
      " 119    18.13    2.35926569438       19   0.520271700638   0.524329356393     28.03m\n",
      " 120    18.29    2.15700860841       19    0.52021830417   0.524805960318     27.94m\n",
      " 121    18.13    4.53989727792       19    0.51999260887   0.526815160936     27.84m\n",
      " 122    18.57    12.9537811478       19   0.520182508434   0.525125194834     27.75m\n",
      " 123    17.35     10.008680496       19   0.520013666239   0.526628063596     27.65m\n",
      " 124     19.3    11.3936290387       19   0.519998311472   0.526764499919     27.57m\n",
      " 125    17.99    10.2390883898       19   0.519802687957   0.528499297991     27.48m\n",
      " 126    18.46    18.4874117774       21   0.520090909828    0.52594110986     27.38m\n",
      " 127    20.53    4.79887444472       21   0.520145164637   0.525458005203     27.30m\n",
      " 128    18.17    12.4335572302       19   0.520042886479     0.5263683154     27.20m\n",
      " 129    19.02     10.714060496       23   0.519749159048   0.528972889898     27.11m\n",
      " 130    19.19    4.69042745893       19   0.520114831224   0.525728165938     27.02m\n",
      " 131    18.85    16.7136698349       19   0.520353058452   0.525799435037     26.93m\n",
      " 132    18.88     22.270805747       19   0.520166181475   0.525270730644     26.84m\n",
      " 133    17.72     30.877504415       17   0.520638393216   0.523251172956     26.74m\n",
      " 134    18.31    5.84086869179       19   0.520289003023   0.526369613064     26.66m\n",
      " 135    15.01    62.7708765284       17   0.520100043443   0.528047608891     26.57m\n",
      " 136    17.63    27.6856828205       17   0.520005016821   0.528889221346     26.48m\n",
      " 137    18.54     1.9617535278       17   0.520405005713   0.525336529659     26.39m\n",
      " 138    18.34    4.37033049503       17    0.52016847362    0.52744062327     26.31m\n",
      " 139    28.82    4.07111281913       17   0.520566801549   0.523891838666     26.30m\n",
      " 140    17.33    3.51712216528       17   0.520369108001   0.525656464922     26.20m\n",
      " 141     16.3    21.9166871612       17    0.52016555623   0.527466516834     26.10m\n",
      " 142    16.94    23.7273619853       22   0.520184134848   0.527301596411     26.00m\n",
      " 143    18.48    4.13644529586       17   0.520256691165   0.526656970499     25.90m\n",
      " 144     17.9    1990.28263503       17   0.520073768504   0.528280464928     25.80m\n",
      " 145    19.22    22.3518005039       17   0.520052942389    0.52846495067     25.72m\n",
      " 146    16.82    9.93405629035       17   0.520507971743   0.524417648257     25.61m\n",
      " 147    16.55    76.1301979085       17   0.520338195878   0.525931792933     25.51m\n",
      " 148    18.14    1.74678430719       17   0.520637058517   0.523263125007     25.42m\n",
      " 149    17.16    12.2827960701       17   0.520303894972   0.526237116407     25.31m\n",
      " 150    16.11    1.80164588665       17   0.520420305568   0.525200105081     25.20m\n",
      " 151    16.13    1.89833494921       17   0.520321603085   0.526079515391     25.10m\n",
      " 152    15.76    3.36001508158       17   0.519886080989   0.529940488602     24.99m\n",
      " 153    16.79    1.81929842654       17   0.520190431342    0.52724569006     24.89m\n",
      " 154    16.48     136.35524425       17   0.519864667766    0.53012951193     24.79m\n",
      " 155     16.0    18.5107715974       17   0.520285374085   0.526401894832     24.69m\n",
      " 156     23.5    19.0349366258       19   0.520337755665   0.525935712662     24.63m\n",
      " 157    18.05    2.27454857667       17   0.520328719906   0.526016161351     24.53m\n",
      " 158    15.24    199.934898032       17   0.520295881817    0.52630841567     24.42m\n",
      " 159    16.32    5.78177688752       17   0.519940106367   0.529463249802     24.32m\n",
      " 160     16.5    1.44751670859       17   0.519973503558   0.529167992132     24.21m\n",
      " 161    17.01     21.148438166       17   0.520274420253   0.526499322918     24.11m\n",
      " 162    17.25    5.79155648284       17   0.520251582446    0.52670238763     24.01m\n",
      " 163    16.57    10.1737881846       17   0.520476791736   0.524696091506     23.90m\n",
      " 164    19.07    9.74386354414       17   0.520215655644   0.527021658101     23.81m\n",
      " 165    16.86    1.43322571261       17   0.519824785722   0.530481366874     23.71m\n",
      " 166    16.07    1.96740414961       17   0.520412218962   0.525272216027     23.60m\n",
      " 167    19.14    1.92017869775       17    0.52019806933    0.52717786376     23.51m\n",
      " 168    16.34    1.73839528341       17   0.519929758646   0.529554694614     23.40m\n",
      " 169    16.82    10.7627156963       17   0.520183926942   0.527303442287     23.30m\n",
      " 170    17.98    13.4499930069       19   0.520006960902   0.528872018358     23.20m\n",
      " 171    17.42    11.9889247676       17   0.520066105376   0.528348356216     23.10m\n",
      " 172    17.22    5.85435091317       17   0.520360858141   0.525729960459     23.00m\n",
      " 173    17.25    3.75546698682       19   0.520152179893   0.527585221591     22.90m\n",
      " 174    16.11    11.2174162998       17   0.520105481222   0.527999403445     22.79m\n",
      " 175    18.79     94.618026574       17   0.520159257805   0.527522414239     22.70m\n",
      " 176    17.58     12.156264803       17   0.520304985842   0.526227409258     22.60m\n",
      " 177    18.29    2.69668361725       19   0.520076224881   0.526964392695     22.50m\n",
      " 178    18.11    22.9253687117       19   0.520159929487   0.524907928872     22.41m\n",
      " 179    17.35     37.472423986       19   0.520126170684   0.525208911121     22.30m\n",
      " 180    19.09    1.36582335895       19   0.520058985378   0.527117493995     22.21m\n",
      " 181    16.82     5.8519142533       17   0.520064951777   0.528358575653     22.10m\n",
      " 182    16.36    8.40098670614       19   0.520116423592   0.526607201672     22.00m\n",
      " 183    17.17    631.122163098       17   0.520378893003   0.525569278437     21.89m\n",
      " 184    16.27    1.74923066781       17      0.520230412   0.526890548972     21.79m\n",
      " 185    19.98    5.02949026128       17    0.52015858372   0.527528396238     21.70m\n",
      " 186    17.86    10.0906003906       17   0.520221170385   0.526972664294     21.60m\n",
      " 187    17.39    1.37887236763       17   0.520263027792   0.526600631058     21.50m\n",
      " 188     17.0    27.9485856546       17   0.520335218642   0.525958302096     21.40m\n",
      " 189    17.81    555.900684892       17   0.520302971226   0.526245336242     21.30m\n",
      " 190    15.27    8.62371961322       17   0.520091611085   0.528122351335     21.19m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 191    17.62    1.38929789014       17   0.520497437544   0.524511739015     21.09m\n",
      " 192    21.16    2.17349096363       17   0.520079191296   0.528232415963     21.00m\n",
      " 193    16.23    2.33258268782       17   0.520250919766   0.526708278614     20.91m\n",
      " 194    15.92    21.0676944856       17   0.520429371377   0.530178083414     20.80m\n",
      " 195    15.78    20.1617052472       17   0.519959567586   0.529291219513     20.69m\n",
      " 196    16.66    7.42430100727       17   0.519527483354   0.533096119946     20.58m\n",
      " 197    16.41     3.3142452362       17   0.520254038984   0.526680549254     20.48m\n",
      " 198     17.4    10.6018109753       17   0.520347777041   0.525846472621     20.38m\n",
      " 199    16.32    3.79345507719       17   0.520318502835   0.526107111205     20.27m\n",
      " 200    16.65    11.5179567664       17   0.520020488399   0.528752297592     20.17m\n",
      " 201    16.29     5.2845647217       17   0.520045698444   0.528529103501     20.06m\n",
      " 202    16.42    1.52852533098       17   0.520092760275   0.528112165874     19.96m\n",
      " 203    21.65    10.2326217738       17   0.520044333856   0.528541187406     19.88m\n",
      " 204    15.64    13.0556709139       17   0.520072572126   0.528291064848     19.77m\n",
      " 205     17.6    12.0713672228       17   0.520133611157   0.527749955604     19.67m\n",
      " 206    17.19     4.2422730354       17   0.520038612402   0.528591849535     19.57m\n",
      " 207    17.21    20.3087264486       17   0.519874212305   0.530045267648     19.46m\n",
      " 208    16.57    4.30120453314       17   0.520500631205   0.524483215431     19.36m\n",
      " 209     15.9    21.3516797904       17   0.519909285424   0.529735568557     19.25m\n",
      " 210    18.67    12.6874037489       19   0.520027650573   0.528688898831     19.15m\n",
      " 211    17.31     12.880959413       17   0.520440293585   0.525021817992     19.05m\n",
      " 212    17.83    1.48368103614       17   0.520181470088   0.527325254727     18.95m\n",
      " 213    16.75    1.32880874253       17   0.520620835603   0.523408374778     18.84m\n",
      " 214    17.25    24.2263616181       17   0.520272458815   0.526516766665     18.74m\n",
      " 215    16.91    5.67924652229       17   0.520115195128   0.527913278283     18.64m\n",
      " 216    17.73    3.90480993923       17   0.520347051672   0.525618064813     18.54m\n",
      " 217    17.17    22.5703256834       19    0.51989827387   0.529832823407     18.43m\n",
      " 218    19.15    12.7042224363       17   0.520422151267   0.525183644818     18.34m\n",
      " 219    17.61     2.1287003319       17   0.520232369623   0.526638740137     18.24m\n",
      " 220    16.64    15.5387600664       30   0.520442609208    0.52744736172     18.14m\n",
      " 221    15.86    30.9835894629       17   0.520285751022   0.526163917618     18.03m\n",
      " 222    16.57    5.07681614491       17   0.520401369378    0.52513386383     17.92m\n",
      " 223    17.24    16.5154722457       17   0.519595394958   0.532268170702     17.82m\n",
      " 224     18.2    2.01248003308       17   0.520049603104   0.528260831375     17.72m\n",
      " 225    15.24    7.87453712363       17   0.520049465168   0.528262053488     17.61m\n",
      " 226    16.77    3.30545514032       17   0.520135401213    0.52750004728     17.51m\n",
      " 227    15.96    16.9911576676       17   0.520112196002   0.527705931795     17.41m\n",
      " 228     17.5    1.45639224073       19   0.520099761498    0.52781621812     17.30m\n",
      " 229    16.75    92.1648550638       19   0.520245073284   0.526525785504     17.20m\n",
      " 230     16.7    7.44466111456       17   0.520013520782   0.528580413952     17.09m\n",
      " 231    17.94    7.38166049753       21   0.520492639284   0.524319141165     17.00m\n",
      " 232     16.7    21.4544422761       17   0.520312390848   0.525926780284     16.89m\n",
      " 233    15.65    9.89044935362       17   0.520296052445   0.526072232482     16.79m\n",
      " 234    16.71    3.52183149767       17   0.520446139537   0.524734398014     16.68m\n",
      " 235    17.65    3.95042751948       17    0.52025542013    0.52643376656     16.58m\n",
      " 236    17.13    20.8239972966       17   0.519866610438   0.529879386491     16.48m\n",
      " 237     16.7     15.594950382       17   0.520561898878   0.523699952622     16.37m\n",
      " 238    16.62    4.19609128816       17   0.520243857459   0.526771055412     16.27m\n",
      " 239    16.52    2.10858266217       17   0.520487166368   0.524603462376     16.17m\n",
      " 240    17.75    1.90490866537       17     0.5199418889   0.529214222953     16.07m\n",
      " 241    17.32    4.13064505057       17   0.520364142264   0.525465768753     15.97m\n",
      " 242    21.08    16.5795940527       17   0.520222349617   0.526727814002     15.88m\n",
      " 243    17.64     28.342568165       17   0.520393164469   0.525207036207     15.78m\n",
      " 244    18.51    1.02728485668       17   0.520401468405   0.525368065245     15.68m\n",
      " 245    18.69    22.3688743031       17   0.520101555666   0.527800306546     15.58m\n",
      " 246    34.54    2.61784829027       17   0.520253685915    0.52644919093     15.52m\n",
      " 247    15.57    9.81993155995       17   0.520348710614   0.525603283959     15.42m\n",
      " 248    17.13     1561.7122424       17   0.520099566426   0.527817948081     15.32m\n",
      " 249    17.34    1.65210703563       17   0.520385626353   0.525274252043     15.22m\n",
      " 250    16.34    19.0104268947       17       0.51972972   0.531086574968     15.11m\n",
      " 251    15.94    22.5245432981       17   0.520363839412   0.525468467932     15.01m\n",
      " 252    17.48    2.77291386014       17   0.520387552429   0.525602198885     14.91m\n",
      " 253    17.37    50.2841315244       17   0.520293002698   0.526443945987     14.80m\n",
      " 254    16.63    4.75361118915       21   0.519810748172   0.529599957817     14.70m\n",
      " 255    16.81    7.41970099782       19   0.520270741331   0.525393423248     14.60m\n",
      " 256    17.28    25.1054544932       19   0.519954894458   0.528199953863     14.49m\n",
      " 257    17.41    34.3036860349       17   0.520214613947   0.526796569565     14.39m\n",
      " 258    16.39    1.90750476481       17   0.520223698638    0.52671582272     14.29m\n",
      " 259     17.0    4.53961316874       17   0.519723966024   0.531478552235     14.19m\n",
      " 260    19.87    39.4428628619       17   0.519939746626   0.529575694235     14.09m\n",
      " 261    18.34    2.42303751628       17   0.520461842863   0.524939759617     13.99m\n",
      " 262    17.27    22.8977378914       17   0.520188063295   0.527376437433     13.89m\n",
      " 263    16.74    18.2831981069       17   0.520111772979   0.528053201569     13.78m\n",
      " 264    15.97    39.3753859723       17    0.52021964222   0.527096020426     13.68m\n",
      " 265    17.85    63.5194098232       17   0.520280682349   0.526553519907     13.58m\n",
      " 266    18.42    14.5417297262       17   0.520552971826   0.524125900279     13.48m\n",
      " 267    16.57    18.9091856157       30    0.52012707041   0.530624925988     13.37m\n",
      " 268    17.73     16.739236135       17   0.520044537362    0.52864884196     13.27m\n",
      " 269    22.31    21.5702728221       19   0.520197110358   0.527296117597     13.18m\n",
      " 270    32.64    21.4704911774       19   0.520202591675   0.527247447824     13.11m\n",
      " 271    18.61    1.76668285433       21   0.520153088395   0.526530067948     13.01m\n",
      " 272     17.4    15.8274724521       19   0.520372441082   0.525736831308     12.91m\n",
      " 273    17.14    5.77387616845       21   0.520067645256    0.52844421351     12.81m\n",
      " 274    17.36    21.8830881164       34   0.520307723334   0.526139297923     12.70m\n",
      " 275    19.07    13.9939296261       19   0.520120408922   0.527976641464     12.60m\n",
      " 276    20.34    16.3647000037       39   0.519865061147   0.530235169191     12.51m\n",
      " 277    20.21    16.3687726425       17   0.519875028068   0.530147213896     12.41m\n",
      " 278    16.84    17.8935843131       17    0.52028119549   0.526548956673     12.31m\n",
      " 279     15.7    5.83783241276       17   0.520539488853   0.524246403348     12.20m\n",
      " 280    16.49    16.8661242244       17   0.519911465752   0.529825522892     12.10m\n",
      " 281    17.86    36.4184598222       17   0.519939181379   0.529580688822     12.00m\n",
      " 282    19.28    16.3324780105       17   0.519973278136   0.529279311905     11.90m\n",
      " 283    18.99    23.8487171368       17   0.520160893129    0.52675282313     11.80m\n",
      " 284     17.0    29.1063543601       19   0.519949488842   0.528627915815     11.70m\n",
      " 285    17.59    278244.869482       17   0.520270310794   0.525779394553     11.59m\n",
      " 286    16.92     23.402441939       19    0.52025765253   0.525892110784     11.49m\n",
      " 287    16.96    3.54146952117       17   0.520049240945   0.527744069661     11.39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 288    16.47    21.9275434571       17   0.520131563317   0.527013413962     11.28m\n",
      " 289    23.48    23.0192008393       17   0.520075925431   0.527507353903     11.19m\n",
      " 290    15.03    23.4486342132       17   0.520062832918   0.527623511235     11.09m\n",
      " 291    16.55    1.62768159975       17   0.519619093431   0.531543661736     10.98m\n",
      " 292    16.25    71.6377179132       17   0.519799613335   0.529952787836     10.88m\n",
      " 293    17.09    26.3998899972       17   0.520397346269   0.524646706684     10.78m\n",
      " 294    17.57    41.9545144333       17   0.520191525433   0.526480506462     10.67m\n",
      " 295    16.57    1.50507144279       17   0.520051072277   0.523809530605     10.57m\n",
      " 296    16.75    41.7643347605       17   0.520042019164   0.527808113118     10.47m\n",
      " 297     17.2    267.744704944       17   0.520414312575   0.520552594584     10.37m\n",
      " 298    16.65    5.68327292357       17   0.520120064771   0.523192654804     10.26m\n",
      " 299    20.06    81.4523527793       17    0.51951186425   0.528603108208     10.17m\n",
      " 300     17.3    23.0736651444       17   0.519874689372   0.525382942189     10.06m\n",
      " 301    15.82    22.5451519656       17   0.519949195378   0.524718957124      9.96m\n",
      " 302    16.72    7.52898518856       17   0.519689284948   0.527031193093      9.86m\n",
      " 303    17.14    43.8510699944       17   0.519729909483   0.526670531312      9.76m\n",
      " 304    16.45    47.5964192968       17   0.519592229069   0.527891736929      9.65m\n",
      " 305    15.29    25.6476420716       17   0.520019952967   0.524087510271      9.55m\n",
      " 306    16.54    4.89673406221       17   0.519739426462   0.526586000449      9.45m\n",
      " 307    15.94    20.9063341297       17   0.519792682457   0.526112695539      9.34m\n",
      " 308    17.44    1.47076507956       17   0.519633016978   0.527530282406      9.24m\n",
      " 309    17.59    4.43814550743       17   0.519727953709   0.526687900835      9.14m\n",
      " 310    16.57    63.6859160356       17   0.519720695819   0.526752353702      9.04m\n",
      " 311    15.92    47.2095592941       17   0.519584788753   0.527957641816      8.94m\n",
      " 312    15.93    2.39098059766       17   0.519823565043   0.525838013662      8.83m\n",
      " 313    17.42    2.96447193032       17   0.519786457195   0.526168046129      8.73m\n",
      " 314    15.76    24.7459747902       21   0.519724240392   0.526720877621      8.63m\n",
      " 315    24.66    1.68676258805       21   0.519394726592   0.529638076531      8.53m\n",
      " 316    17.96    28.9331110036       17   0.519983181595   0.524415766802      8.43m\n",
      " 317    18.14    4.19890195565       17   0.519543912584   0.528319551588      8.33m\n",
      " 318    20.32    22.5369260584       21      0.519938349   0.524815676398      8.23m\n",
      " 319    17.33     3.8360730136       17   0.519636178802   0.527502251413      8.13m\n",
      " 320    17.49    23.1895855479       17   0.519671320575   0.527190591884      8.03m\n",
      " 321    18.44    24.4874306899       17   0.519553955662   0.528230657714      7.93m\n",
      " 322    17.75    4.09823312924       19   0.519936761181   0.524829833627      7.83m\n",
      " 323     15.7    63.5331858117       19   0.519628055852   0.527574261691      7.72m\n",
      " 324    18.67     4.1806689996       17   0.519458439984   0.529075417723      7.62m\n",
      " 325    15.26    4.09714815586       17   0.519879776143   0.525337639452      7.52m\n",
      " 326    19.86     42.824135424       17   0.519952575469   0.524688812142      7.42m\n",
      " 327    15.84    8.87990904867       17   0.520113225549   0.523253841792      7.31m\n",
      " 328    16.85    2.08099299471       17    0.51967415823   0.527165416798      7.21m\n",
      " 329    17.54    4.05077873403       19   0.519942165262   0.524781648304      7.11m\n",
      " 330    18.21     23.515646861       17   0.520029388785   0.524003240211      7.01m\n",
      " 331    17.29    7.45992930129       19   0.519493857295   0.528762355396      6.91m\n",
      " 332    16.63    167.363013248       17   0.519815563705   0.525909196047      6.80m\n",
      " 333    16.02    4.64827671092       17   0.519906830567    0.52509661988      6.70m\n",
      " 334    15.61    2.14317818061       19   0.519613473041    0.52770351141      6.60m\n",
      " 335    17.67    4.57369257163       19    0.51993992781   0.524801599079      6.50m\n",
      " 336    17.83    2.66950648887       17   0.519689778003   0.527026817434      6.40m\n",
      " 337    17.42    2.46861348908       17   0.519693268851    0.52699583644      6.29m\n",
      " 338    16.38    64.1856581144       17   0.519765700051   0.526352556997      6.19m\n",
      " 339    15.92    6.62668435804       17   0.519454305608   0.529111949021      6.09m\n",
      " 340     17.4    143.685539595       17   0.520431269423   0.520399999985      5.99m\n",
      " 341    16.26    2.50123341104       17   0.520086206941   0.523495485552      5.89m\n",
      " 342    16.75    21.9288615953       17   0.519682624871   0.527090294557      5.79m\n",
      " 343    16.17    23.2177509789       17   0.519715845171   0.526795424423      5.68m\n",
      " 344    21.66    2.01587113801       17   0.519784623233   0.526184351167      5.58m\n",
      " 345     17.3    7.52368591659       17   0.519662498349   0.527268852277      5.48m\n",
      " 346    16.85    43.3807714528       17   0.519988156805   0.524371366677      5.38m\n",
      " 347    18.38     1.8129948481       19   0.519583532592   0.527968767742      5.28m\n",
      " 348    16.32    2.83900100125       17   0.519957463265   0.524645217436      5.18m\n",
      " 349    18.03    42.2090021132       17   0.519828867656   0.525790834051      5.08m\n",
      " 350    16.43    45.7470009369       17   0.519702413607   0.526914667856      4.97m\n",
      " 351    15.81    25.1995350696       17   0.520066572872   0.523671007074      4.87m\n",
      " 352    21.02    1.59336653859       19   0.520166924636   0.522773209464      4.77m\n",
      " 353    16.09    1.88957914486       17   0.519842279568   0.525671481516      4.67m\n",
      " 354    18.92    2.04371268842       19   0.519689369005   0.527030447126      4.57m\n",
      " 355    17.76    2.35422390116       19   0.519635703605   0.527506464351      4.47m\n",
      " 356    16.83    21.4892716909       17   0.519876719161   0.525364865434      4.36m\n",
      " 357     18.9    21.8235852349       17   0.519756667556   0.526432824621      4.26m\n",
      " 358     17.8    22.8632084281       19   0.519535140086   0.528397185585      4.16m\n",
      " 359    18.89     1.9998011054       19   0.519756325654    0.52643586268      4.06m\n",
      " 360    17.75    24.8045051004       17   0.519962762182    0.52459795134      3.96m\n",
      " 361    16.94    1843.30078926       19   0.519816593265   0.525900037359      3.86m\n",
      " 362    16.84    24.8350454155       19   0.519861703062   0.525498578423      3.76m\n",
      " 363    16.44    4.89507877344       17    0.51954552864   0.528305248583      3.65m\n",
      " 364    16.16    7.54305353364       21   0.519647313395   0.527403524993      3.55m\n",
      " 365    17.45    169.038700661       17   0.519983593891   0.524412087512      3.45m\n",
      " 366     15.7    21.7203626739       17   0.519939030929   0.524809596089      3.35m\n",
      " 367    17.86    22.1610503207       17   0.519765793541   0.526351726126      3.25m\n",
      " 368    17.52     5.2008175465       17   0.519793798099   0.526102775361      3.14m\n",
      " 369    16.49    16.5982615581       17   0.519678418346   0.527127619415      3.04m\n",
      " 370     16.6    44.8897208948       17   0.519342827177   0.530095912723      2.94m\n",
      " 371    18.83    6.66769590741       17   0.519755823799   0.526440321999      2.84m\n",
      " 372    17.12    40.9645709089       17   0.519881211407    0.52532485622      2.74m\n",
      " 373    17.77    4.40702872152       17   0.519812397058   0.525937364553      2.64m\n",
      " 374    15.93    24.2508170967       17   0.519930392861   0.524886610233      2.54m\n",
      " 375    17.75    7.12175156294       17   0.519620123469   0.527644572016      2.43m\n",
      " 376    16.85    2.94433888499       17   0.519790768793   0.526129711162      2.33m\n",
      " 377     17.2    2.03748883355       17     0.5198559994   0.525549357572      2.23m\n",
      " 378    17.95    21.8027527778       17   0.519814847745    0.52591556492      2.13m\n",
      " 379    16.02    22.3361074833       17   0.519840550778   0.525686867706      2.03m\n",
      " 380    16.51    1286.57578364       17   0.519657987511   0.527308862117      1.93m\n",
      " 381    18.07    5.59803258289       17   0.519739357169   0.526586615966      1.82m\n",
      " 382    19.49    81.3894484811       17   0.519965066681   0.524577393844      1.72m\n",
      " 383     18.0    45.0510430652       17   0.519643337911   0.527438776533      1.62m\n",
      " 384    17.41    20.9417731181       17   0.519646994713   0.527406350919      1.52m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 385    15.99    103.885351622       18   0.519636518345   0.526810529948      1.42m\n",
      " 386    17.31    1.42493716516       17   0.519187522155   0.531463323942      1.32m\n",
      " 387    15.95    25.3488045437       17   0.520064268679   0.523691601441      1.22m\n",
      " 388    19.83    22.9352484853       17   0.519415342862   0.529456085354      1.12m\n",
      " 389    19.33    3.36796952649       19    0.51991390424   0.525033582383      1.01m\n",
      " 390    17.46    49.5515243393       18   0.519951140058   0.524009225838     54.77s\n",
      " 391    18.23    4.73518852338       17   0.519976515667   0.524475248783     48.69s\n",
      " 392    17.44     24.992621569       18   0.519466558347   0.528316925779     42.60s\n",
      " 393    18.65    21.3971487118       17   0.519723305756   0.526729177462     36.52s\n",
      " 394    17.81    44.0541388495       17   0.519792840585   0.526111289491     30.44s\n",
      " 395    16.17     31.176603778       17   0.519964092413      0.524586085     24.34s\n",
      " 396    17.22    4.66010652277       17   0.519717191426   0.526783470915     18.26s\n",
      " 397    14.99     1.9136454106       18   0.519361273749   0.529383994057     12.17s\n",
      " 398    18.99     6.6056181016       17    0.51989386593   0.525212133225      6.09s\n",
      " 399    15.71    28.1332394389       21   0.519687844436   0.527043976807      0.00s\n",
      "\n",
      "Details about the results using Genetic Programming\n",
      "\n",
      "log(max(X13, add(div(add(8.326, 9.155), mul(X10, X3)), max(max(max(log(mul(X6, X5)), X5), X5), X5))))\n",
      "R2(max) =  0.584859137123\n",
      "Raw fitness =  0.519687844436\n",
      "OOB fitness =  0.527043976807\n",
      "Depth       =  8\n",
      "Length      =  21 \n",
      "\n",
      "Finished Genetic Programming\n",
      "Total processing time 42.390514087677005 min\n"
     ]
    }
   ],
   "source": [
    "if (regressor == 3):    \n",
    "    print('Starting Genetic Programming')\n",
    "    \n",
    "    '''\n",
    "    http://gplearn.readthedocs.io/en/stable/reference.html\n",
    "    \n",
    "    The sum of p_crossover, p_subtree_mutation, p_hoist_mutation and p_point_mutation \n",
    "    should total to 1.0 or less.\n",
    "    '''\n",
    "    \n",
    "    gp = SymbolicRegressor(function_set=('add', 'sub', 'mul', 'div','max','min','log','sqrt'),\n",
    "                           population_size       = 100, \n",
    "                           const_range           = (-10, 100),\n",
    "                           generations           = 100, \n",
    "                           stopping_criteria     = 0.001,\n",
    "                           p_crossover           = 0.5, \n",
    "                           p_subtree_mutation    = 0.25,\n",
    "                           p_hoist_mutation      = 0.05, \n",
    "                           p_point_mutation      = 0.20, \n",
    "                           init_depth            = (6, 12),\n",
    "                           max_samples           = 0.7, \n",
    "                           verbose               = 1, \n",
    "                           n_jobs                = -1, \n",
    "                           metric                = 'rmse',\n",
    "                           parsimony_coefficient = 0.0001, \n",
    "                           random_state          = 1121)  \n",
    "                           # seed is relevant to stochastic approaches such as genetic programming\n",
    "                           \n",
    "    gp.fit(train_x, train_y)\n",
    "    predict_y = gp.predict(test_x)  \n",
    "    predict_y[predict_y < 0] = 0        # only positive values\n",
    "    \n",
    "    print ('\\nDetails about the results using Genetic Programming\\n')  \n",
    "    print (gp._program)\n",
    "    print ('R2(max) = ',gp.score(train_x, train_y))  \n",
    "\n",
    "    # summary of the results\n",
    "    print('Raw fitness = ',gp._program.raw_fitness_)    \n",
    "    #print('Fitness     = ',gp._program.fitness_)    \n",
    "    print('OOB fitness = ',gp._program.oob_fitness_)    \n",
    "    print('Depth       = ',gp._program.depth_)    \n",
    "    print('Length      = ',gp._program.length_,'\\n')    \n",
    "\n",
    "    '''\n",
    "    Comments:\n",
    "    raw_fitness_ : The raw fitness of the individual program.\n",
    "    fitness_     : The penalized fitness of the individual program.\n",
    "    oob_fitness_ : The out-of-bag raw fitness of the individual program for the held-out samples. \n",
    "                     Only present when sub-sampling was used in the estimator by \n",
    "                     specifying max_samples < 1.0.\n",
    "    depth_       : The maximum depth of the program tree.\n",
    "    length_      : The number of functions and terminals in the program.\n",
    "    '''\n",
    "    print('Finished Genetic Programming')\n",
    "\n",
    "\n",
    "if (regressor == 4):    \n",
    "    print('Starting Genetic Programming')\n",
    "    \n",
    "    '''\n",
    "    http://gplearn.readthedocs.io/en/stable/reference.html\n",
    "    \n",
    "    The sum of p_crossover, p_subtree_mutation, p_hoist_mutation and p_point_mutation \n",
    "    should total to 1.0 or less.\n",
    "    '''\n",
    "    \n",
    "    gp = SymbolicRegressor(function_set=('add', 'sub', 'mul', 'div','max','min','log','sqrt'),\n",
    "                           population_size       = 100, \n",
    "                           const_range           = (-10, 100),\n",
    "                           generations           = 400, \n",
    "                           stopping_criteria     = 0.001,\n",
    "                           p_crossover           = 0.55, \n",
    "                           p_subtree_mutation    = 0.20,\n",
    "                           p_hoist_mutation      = 0.05, \n",
    "                           p_point_mutation      = 0.20, \n",
    "                           init_depth            = (6, 12),\n",
    "                           max_samples           = 0.9, \n",
    "                           verbose               = 1, \n",
    "                           n_jobs                = -1, \n",
    "                           metric                = 'rmse',\n",
    "                           parsimony_coefficient = 0.0001, \n",
    "                           random_state          = 343)  \n",
    "                           # seed is relevant to stochastic approaches such as genetic programming\n",
    "                           \n",
    "    gp.fit(train_x, train_y)\n",
    "    predict_y = gp.predict(test_x)  \n",
    "    predict_y[predict_y < 0] = 0        # only positive values\n",
    "    \n",
    "    print ('\\nDetails about the results using Genetic Programming\\n')  \n",
    "    print (gp._program)\n",
    "    print ('R2(max) = ',gp.score(train_x, train_y))  \n",
    "\n",
    "    # summary of the results\n",
    "    print('Raw fitness = ',gp._program.raw_fitness_)    \n",
    "    #print('Fitness     = ',gp._program.fitness_)    \n",
    "    print('OOB fitness = ',gp._program.oob_fitness_)    \n",
    "    print('Depth       = ',gp._program.depth_)    \n",
    "    print('Length      = ',gp._program.length_,'\\n')    \n",
    "\n",
    "    '''\n",
    "    Comments:\n",
    "    raw_fitness_ : The raw fitness of the individual program.\n",
    "    fitness_     : The penalized fitness of the individual program.\n",
    "    oob_fitness_ : The out-of-bag raw fitness of the individual program for the held-out samples. \n",
    "                     Only present when sub-sampling was used in the estimator by \n",
    "                     specifying max_samples < 1.0.\n",
    "    depth_       : The maximum depth of the program tree.\n",
    "    length_      : The number of functions and terminals in the program.\n",
    "    '''\n",
    "    print('Finished Genetic Programming')\n",
    "\n",
    "\n",
    "#------------------------------------------------ end regressors\n",
    "\n",
    "test['visitors'] = np.expm1(predict_y)\n",
    "\n",
    "fname = 'submissionr v01 regressor ' + str(regressor) + '.csv'\n",
    "\n",
    "test[['id', 'visitors']].to_csv(fname, index=False, float_format='%.3f')  \n",
    "\n",
    "nm=(time.time() - start_time)/60\n",
    "print (\"Total processing time %s min\" % nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
